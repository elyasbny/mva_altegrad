{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlAfI8mCWAf3"
      },
      "source": [
        "<center><h2>ALTeGraD 2023<br>Lab Session 3: Transfer learning for NLP</h2> 24 / 10 / 2023<br> Dr. G. Shang, H. Abdine<br><br>\n",
        "\n",
        "\n",
        "<b>Student name:</b> BENYAMINA Elyas\n",
        "\n",
        "</center>\n",
        "\n",
        "<br><br>\n",
        "In this lab we will:\n",
        "* Implement and pretrain a language model with transformer architecture.\n",
        "* Use the pretrained model (transfer learning) to perform a sentiment analysis task which consists of classifying some books reviews into positive and negative ones.\n",
        "* Compare the performance of the pretrained model to a model trained from scratch.\n",
        " <br>\n",
        "\n",
        "<b>The deadline for this lab is October 31, 2023 11:59 PM.</b> More details about the submission and the architecture for this lab can be found in the handout PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IqukuIe0Rb_c"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FF6fjkqgN39"
      },
      "source": [
        "### The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "p0cj9WkSFQwl"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        '''\n",
        "        ntokens: the size of vocabulary\n",
        "        nhid: the hidden dimension of the model.\n",
        "        We assume that embedding_dim = nhid\n",
        "        nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "        nhead: the number of heads in the multiheadattention models\n",
        "        dropout: the dropout value\n",
        "         '''\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.encoder = nn.Embedding(ntoken,nhid) # fill me, nhid = the dim_embed\n",
        "        self.pos_encoder = PositionalEncoding(nhid) #fill me, the PositionalEncoding class is implemented in the next cell\n",
        "        encoder_layers = nn.TransformerEncoderLayer(nhid,nhead,nhid) #fill me we assume nhid = d_model = dim_feedforward\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers,nlayers) #fill me\n",
        "        self.nhid = nhid\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.nhid)\n",
        "        src = self.pos_encoder(src) #fill me\n",
        "        output = self.transformer_encoder(src, src_mask) #fill me\n",
        "        return output\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, nhid, nclasses):\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.decoder = nn.Linear(nhid, nclasses)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src):\n",
        "        output = self.decoder(src)\n",
        "        return output\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, nclasses, dropout=0.5):\n",
        "        super(Model, self).__init__()\n",
        "        self.base = TransformerModel(ntoken, nhead, nhid, nlayers, dropout=dropout) #fill me\n",
        "        self.classifier = ClassificationHead(nhid, nclasses) #fill me\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        # base model\n",
        "        x =  self.base.forward(src, src_mask) #fill me\n",
        "        # classifier model\n",
        "        output = self.classifier.forward(x) #fill me\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kt2QQohaFZry"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, nhid, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, nhid)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, nhid, 2).float() * (-math.log(10000.0) / nhid)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfEYHJx2JW6l"
      },
      "source": [
        "Let's verify if our model works, by applying one inference step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "rhb2gkUhJMR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "416241db-4cfa-4acf-aa52-7a8aa75dcaa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 6, 100])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ],
      "source": [
        "ntokens = 100 # the size of vocabulary\n",
        "nhid = 200  # hidden dimension\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
        "dummy_input = torch.tensor([[2, 6, 2, 5, 43, 21]]).to(device)\n",
        "src_mask = model.base.generate_square_subsequent_mask(1).to(device)\n",
        "out = model.forward(dummy_input, src_mask)\n",
        "\n",
        "print(out.shape) # is it the right shape?\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
        "pytorch_total_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwkNklIF0Wxt",
        "outputId": "3fd451c4-f6f7-4b38-918c-99a28febb957"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1008100"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i74NN897Fcit"
      },
      "source": [
        "## Vocabulary and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5qjd26ghWuff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f4d2a54-baab-4439-e996-a8e15743d060"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-31 21:41:34--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 577587 (564K) [text/plain]\n",
            "Saving to: ‘dict.txt.1’\n",
            "\n",
            "dict.txt.1          100%[===================>] 564.05K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-10-31 21:41:35 (80.6 MB/s) - ‘dict.txt.1’ saved [577587/577587]\n",
            "\n",
            "▁d 1\n",
            "es 1\n",
            "▁l 1\n",
            "en 1\n",
            "on 1\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
        "!head -5 dict.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vFdH_-JeFbGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c271a580-3f3e-4ce7-cddd-7681e75e4525"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁trop\n"
          ]
        }
      ],
      "source": [
        "path_vocab = \"dict.txt\"\n",
        "token2ind = {\"<sos>\": 0, \"<pad>\": 1, \"<eos>\": 2, \"<oov>\": 3} # the 4 first indices are reserved to special tokens\n",
        "with open(path_vocab, \"r\") as f:\n",
        "    for idx, line in enumerate(f):\n",
        "        word = line.split()[0].strip()\n",
        "        token2ind[word] =  idx + 4 #fill me\n",
        "\n",
        "ind2token = {token:i for i, token in token2ind.items()} #fill me\n",
        "\n",
        "print(ind2token[1111])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOExGODajN8p"
      },
      "source": [
        "### Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Y0jN-Ar9i5Q1"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        path_documents,\n",
        "        path_labels=None,\n",
        "        token2ind={},\n",
        "        max_len=512,\n",
        "        task=\"language_modeling\",\n",
        "    ):\n",
        "        self.task = task\n",
        "        self.max_len = max_len\n",
        "        self.token2ind = token2ind\n",
        "        self.documents = []\n",
        "        self.labels = []\n",
        "        with open(path_documents, \"r\") as f1:\n",
        "            for line in f1:\n",
        "                self.documents.append(line.strip())\n",
        "        if task == \"classification\":\n",
        "            with open(path_labels, \"r\") as f1:\n",
        "                for line in f1:\n",
        "                    self.labels.append(int(line.strip()))\n",
        "            assert len(self.labels) == len(self.documents)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sequence = self.documents[index].split()\n",
        "        if len(sequence) > self.max_len - 1:\n",
        "            sequence = sequence[: self.max_len - 1]\n",
        "        source_sequence = [self.token2ind[\"<sos>\"]]\n",
        "        for word in sequence:\n",
        "          if word in self.token2ind:\n",
        "            new_tok=self.token2ind[word]\n",
        "          else:\n",
        "            new_tok=self.token2ind[\"<oov>\"]\n",
        "          source_sequence.append(new_tok)\n",
        "        #fill me (constract the input sequence using token2ind, sequence and special tokens)\n",
        "        if self.task == \"language_modeling\":\n",
        "            target = source_sequence[1:]\n",
        "            target.append(self.token2ind[\"<eos>\"])\n",
        "        elif self.task == \"classification\":\n",
        "            target = [self.labels[index]]\n",
        "        sample = {\n",
        "            \"source_sequence\": torch.tensor(source_sequence),\n",
        "            \"target\": torch.tensor(target),\n",
        "        }\n",
        "        return sample\n",
        "\n",
        "\n",
        "def MyCollator(batch):\n",
        "    source_sequences = pad_sequence(\n",
        "        #we use padding to match the length of the sequences in the same batch\n",
        "        [sample[\"source_sequence\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    target = pad_sequence(\n",
        "        [sample[\"target\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    return source_sequences, target.reshape(-1)\n",
        "\n",
        "\n",
        "def get_loader(\n",
        "    path_documents,\n",
        "    path_labels=None,\n",
        "    token2ind={},\n",
        "    max_len=512,\n",
        "    batch_size=32,\n",
        "    task=\"language_modeling\",\n",
        "):\n",
        "    dataset = Dataset(\n",
        "        path_documents,\n",
        "        path_labels=path_labels,\n",
        "        token2ind=token2ind,\n",
        "        max_len=512,\n",
        "        task=task,\n",
        "    )\n",
        "    data_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=MyCollator,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTns4lHrjUTa"
      },
      "source": [
        "## The Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4_jwosiLjRsS"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    path_data_train,\n",
        "    path_labels_train=None,\n",
        "    path_data_valid=None,\n",
        "    save_interval=-1,\n",
        "    log_interval=5,\n",
        "    task=\"language_modeling\",\n",
        "    batch_size=32,\n",
        "):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    ntokens = len(token2ind)\n",
        "    data_loader = get_loader(\n",
        "        path_data_train,\n",
        "        path_labels_train,\n",
        "        token2ind,\n",
        "        task=task,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    losses = []\n",
        "    for idx, data in enumerate(data_loader): #step 1\n",
        "        optimizer.zero_grad()\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n",
        "            device\n",
        "        )\n",
        "        input = data[0].to(device)\n",
        "        output = model(input, src_mask) #step 2\n",
        "        if task == 'classification':\n",
        "            #last vector only\n",
        "            output = output[-1] #fill me\n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        target = data[1]  #fill me\n",
        "        target = target.to(device)\n",
        "        loss = criterion(output, target) #fill me, Cross entropy check next cells\n",
        "        #fill me step 3\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # prevent exploding gradient\n",
        "        #fill me step 4\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} steps | \"\n",
        "                \"loss {:5.5f} | ppl {:8.3f}\".format(\n",
        "                    epoch, idx, len(data_loader), cur_loss, math.exp(cur_loss),\n",
        "                )\n",
        "            )\n",
        "            losses.append(cur_loss)\n",
        "            total_loss = 0\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "pgf6BDB9jUr6"
      },
      "outputs": [],
      "source": [
        "ntokens = len(ind2token) #fill me # the size of vocabulary\n",
        "nhid = 200  # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "nclasses = 2 # for classification task only\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "u-OLy4KIkDwf"
      },
      "outputs": [],
      "source": [
        "# optimization paramerters\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=token2ind['<pad>'])\n",
        "lr = 0.0003  # learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Bwh3n9xZQy4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c918dfb6-e510-4026-bbad-b9fd0a67031c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-31 21:41:51--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10146460 (9.7M) [text/plain]\n",
            "Saving to: ‘pretraining_subset.txt.1’\n",
            "\n",
            "pretraining_subset. 100%[===================>]   9.68M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-10-31 21:41:52 (315 MB/s) - ‘pretraining_subset.txt.1’ saved [10146460/10146460]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
        "path_data_train = \"pretraining_subset.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "0m11g4ScjZaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72aab791-81c2-4e73-e3c6-9fdb01e97fad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 3125 steps | loss 7.37715 | ppl 1599.026\n",
            "| epoch   1 |  1000/ 3125 steps | loss 6.56661 | ppl  710.956\n",
            "| epoch   1 |  1500/ 3125 steps | loss 6.30868 | ppl  549.321\n",
            "| epoch   1 |  2000/ 3125 steps | loss 6.13163 | ppl  460.187\n",
            "| epoch   1 |  2500/ 3125 steps | loss 5.99640 | ppl  401.978\n",
            "| epoch   1 |  3000/ 3125 steps | loss 5.95322 | ppl  384.991\n",
            "| epoch   2 |   500/ 3125 steps | loss 5.64831 | ppl  283.811\n",
            "| epoch   2 |  1000/ 3125 steps | loss 5.63316 | ppl  279.544\n",
            "| epoch   2 |  1500/ 3125 steps | loss 5.56896 | ppl  262.161\n",
            "| epoch   2 |  2000/ 3125 steps | loss 5.54087 | ppl  254.901\n",
            "| epoch   2 |  2500/ 3125 steps | loss 5.54640 | ppl  256.314\n",
            "| epoch   2 |  3000/ 3125 steps | loss 5.47306 | ppl  238.187\n"
          ]
        }
      ],
      "source": [
        "#pretraining on a tiny subset\n",
        "log_interval = 500\n",
        "epochs = 2\n",
        "for epoch in range(1, epochs + 1): #5\n",
        "    train(\n",
        "        path_data_train,\n",
        "        save_interval=-1,\n",
        "        task=\"language_modeling\", # fill me\n",
        "        batch_size=16,\n",
        "        log_interval=log_interval,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeOM1dOvkO4e"
      },
      "source": [
        "## Text Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "-BcBC6FSkMH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8101bbf1-eac1-42af-c017-adcbaea1fec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-31 21:46:53--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88093955 (84M) [application/octet-stream]\n",
            "Saving to: ‘pretrained_model_4layers.pt.2’\n",
            "\n",
            "\r          pretraine   0%[                    ]       0  --.-KB/s               \r         pretrained  76%[==============>     ]  64.29M   321MB/s               \rpretrained_model_4l 100%[===================>]  84.01M   321MB/s    in 0.3s    \n",
            "\n",
            "2023-10-31 21:46:53 (321 MB/s) - ‘pretrained_model_4layers.pt.2’ saved [88093955/88093955]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens).to(device)\n",
        "\n",
        "#load the checkpoint\n",
        "checkpoint = torch.load('pretrained_model_4layers.pt')\n",
        "#load state dict\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "tBRRVsWqlIoQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68e8c7a5-53a4-4ccf-dce9-f6595cc41093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "--2023-10-31 21:47:00--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115362 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘sentencepiece.french.model.1’\n",
            "\n",
            "sentencepiece.frenc 100%[===================>]   1.06M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-10-31 21:47:00 (99.9 MB/s) - ‘sentencepiece.french.model.1’ saved [1115362/1115362]\n",
            "\n",
            "['▁Bonjour', '▁les', '▁amis', '!']\n",
            "Bonjour les amis!\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece   # uncomment this if you are using google colab\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
        "\n",
        "import sentencepiece as spm\n",
        "\n",
        "s = spm.SentencePieceProcessor(model_file='sentencepiece.french.model') #load sentencepiece model\n",
        "\n",
        "#examples\n",
        "encoded = s.encode_as_pieces(\"Bonjour les amis!\")\n",
        "decoded = s.decode_pieces(encoded)\n",
        "print(encoded)\n",
        "print(decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "TtLlV05pkQI3"
      },
      "outputs": [],
      "source": [
        "def infer_next_token(sent):\n",
        "    model.eval()\n",
        "    sent_pieces = s.encode_as_pieces(sent)\n",
        "    source = [token2ind['<sos>']] + [token2ind[el] for el in sent_pieces] # list of tokens\n",
        "    source = torch.tensor(source).to(device)\n",
        "    source = source.reshape(-1, 1)\n",
        "    src_mask = model.base.generate_square_subsequent_mask(source.size(0)).to(device)\n",
        "    out = model(source, src_mask)\n",
        "    next_token_ind = out[-1].argmax(-1) #fill me\n",
        "    return next_token_ind, out\n",
        "\n",
        "def infer_next_tokens(sent, max_len=50):\n",
        "    # to be implemented\n",
        "  i = 0\n",
        "  encoded_word=\"\"\n",
        "  while i<max_len and encoded_word != '<eos>':\n",
        "    next_token_ind, _ = infer_next_token(sent)\n",
        "    encoded_word = ind2token[int(next_token_ind)]\n",
        "    decoded_word = s.decode_pieces([encoded_word])\n",
        "    i+=1\n",
        "    sent += ' ' + decoded_word\n",
        "  return sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "f83Nn5nSly4v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7368a200-b7da-4616-b827-28f730ade279"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Bonjour les gens qui ont été très accueillants et sympathiques . <eos>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "sent = \"Bonjour les\"\n",
        "infer_next_tokens(sent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp7mjVzomoZ3"
      },
      "source": [
        "### Supervised task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "0K1BZsblmEmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d554256f-ccd8-4c2a-d01d-2f1a643edf98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-31 21:47:18--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1495960 (1.4M) [text/plain]\n",
            "Saving to: ‘train.review.spm.1’\n",
            "\n",
            "train.review.spm.1  100%[===================>]   1.43M  --.-KB/s    in 0.009s  \n",
            "\n",
            "2023-10-31 21:47:18 (159 MB/s) - ‘train.review.spm.1’ saved [1495960/1495960]\n",
            "\n",
            "--2023-10-31 21:47:18--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3200 (3.1K) [text/plain]\n",
            "Saving to: ‘train.label.1’\n",
            "\n",
            "train.label.1       100%[===================>]   3.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-31 21:47:18 (42.5 MB/s) - ‘train.label.1’ saved [3200/3200]\n",
            "\n",
            "--2023-10-31 21:47:19--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1864544 (1.8M) [text/plain]\n",
            "Saving to: ‘test.review.spm.1’\n",
            "\n",
            "test.review.spm.1   100%[===================>]   1.78M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-10-31 21:47:19 (151 MB/s) - ‘test.review.spm.1’ saved [1864544/1864544]\n",
            "\n",
            "--2023-10-31 21:47:19--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4000 (3.9K) [text/plain]\n",
            "Saving to: ‘test.label.1’\n",
            "\n",
            "test.label.1        100%[===================>]   3.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-31 21:47:19 (61.5 MB/s) - ‘test.label.1’ saved [4000/4000]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
        "\n",
        "path_data_train = \"train.review.spm\"\n",
        "path_labels_train = \"train.label\"\n",
        "\n",
        "path_data_valid = \"test.review.spm\"\n",
        "path_labels_valid = \"test.label\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "_MLfvjiom2SL"
      },
      "outputs": [],
      "source": [
        "# a function to evaluate the validation accuracy of the model.\n",
        "def evaluate_accuracy(data_loader):\n",
        "    #to be implemented\n",
        "    model.eval()\n",
        "    good_pred=0\n",
        "    total_pred=0\n",
        "    for i, data in enumerate(data_loader):\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(device)\n",
        "        input = data[0].to(device)\n",
        "        target = data[1].to(device)\n",
        "        output = model(input, src_mask)\n",
        "        output = output[-1,:,:].argmax(-1)\n",
        "        total_pred += len(target)\n",
        "        good_pred += (target==output).sum().item()\n",
        "    return good_pred / total_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "qzmx7T7xoa6v"
      },
      "outputs": [],
      "source": [
        "#save the base model to be loaded later in the fine-tuning phase\n",
        "torch.save({\"model_state_dict\": model.base.state_dict(),}, \"pretrained_model_4layers_no_class_head.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "i-xclMCpnVpw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74b21a50-5c9b-4447-f456-1545d1e6c436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====Trainig FROM SCRATCH======\n",
            "| epoch   1 |    50/  200 steps | loss 0.74027 | ppl    2.096\n",
            "| epoch   1 |   100/  200 steps | loss 0.71032 | ppl    2.035\n",
            "| epoch   1 |   150/  200 steps | loss 0.72415 | ppl    2.063\n",
            "| epoch   2 |    50/  200 steps | loss 0.71022 | ppl    2.034\n",
            "| epoch   2 |   100/  200 steps | loss 0.67614 | ppl    1.966\n",
            "| epoch   2 |   150/  200 steps | loss 0.60433 | ppl    1.830\n",
            "| epoch   3 |    50/  200 steps | loss 0.52249 | ppl    1.686\n",
            "| epoch   3 |   100/  200 steps | loss 0.44156 | ppl    1.555\n",
            "| epoch   3 |   150/  200 steps | loss 0.47065 | ppl    1.601\n",
            "| epoch   4 |    50/  200 steps | loss 0.19529 | ppl    1.216\n",
            "| epoch   4 |   100/  200 steps | loss 0.30083 | ppl    1.351\n",
            "| epoch   4 |   150/  200 steps | loss 0.24890 | ppl    1.283\n",
            "| epoch   5 |    50/  200 steps | loss 0.10335 | ppl    1.109\n",
            "| epoch   5 |   100/  200 steps | loss 0.10991 | ppl    1.116\n",
            "| epoch   5 |   150/  200 steps | loss 0.02382 | ppl    1.024\n",
            "| epoch   6 |    50/  200 steps | loss 0.04492 | ppl    1.046\n",
            "| epoch   6 |   100/  200 steps | loss 0.02261 | ppl    1.023\n",
            "| epoch   6 |   150/  200 steps | loss 0.03331 | ppl    1.034\n",
            "| epoch   7 |    50/  200 steps | loss 0.01329 | ppl    1.013\n",
            "| epoch   7 |   100/  200 steps | loss 0.02875 | ppl    1.029\n",
            "| epoch   7 |   150/  200 steps | loss 0.04930 | ppl    1.051\n",
            "| epoch   8 |    50/  200 steps | loss 0.01277 | ppl    1.013\n",
            "| epoch   8 |   100/  200 steps | loss 0.04226 | ppl    1.043\n",
            "| epoch   8 |   150/  200 steps | loss 0.02508 | ppl    1.025\n",
            "| epoch   9 |    50/  200 steps | loss 0.02412 | ppl    1.024\n",
            "| epoch   9 |   100/  200 steps | loss 0.01559 | ppl    1.016\n",
            "| epoch   9 |   150/  200 steps | loss 0.00045 | ppl    1.000\n",
            "| epoch  10 |    50/  200 steps | loss 0.03980 | ppl    1.041\n",
            "| epoch  10 |   100/  200 steps | loss 0.00761 | ppl    1.008\n",
            "| epoch  10 |   150/  200 steps | loss 0.00397 | ppl    1.004\n",
            "| epoch  11 |    50/  200 steps | loss 0.03270 | ppl    1.033\n",
            "| epoch  11 |   100/  200 steps | loss 0.02304 | ppl    1.023\n",
            "| epoch  11 |   150/  200 steps | loss 0.01137 | ppl    1.011\n",
            "| epoch  12 |    50/  200 steps | loss 0.00160 | ppl    1.002\n",
            "| epoch  12 |   100/  200 steps | loss 0.00087 | ppl    1.001\n",
            "| epoch  12 |   150/  200 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch  13 |    50/  200 steps | loss 0.00044 | ppl    1.000\n",
            "| epoch  13 |   100/  200 steps | loss 0.01296 | ppl    1.013\n",
            "| epoch  13 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  14 |    50/  200 steps | loss 0.00005 | ppl    1.000\n",
            "| epoch  14 |   100/  200 steps | loss 0.00101 | ppl    1.001\n",
            "| epoch  14 |   150/  200 steps | loss 0.00011 | ppl    1.000\n",
            "| epoch  15 |    50/  200 steps | loss 0.01110 | ppl    1.011\n",
            "| epoch  15 |   100/  200 steps | loss 0.00555 | ppl    1.006\n",
            "| epoch  15 |   150/  200 steps | loss 0.01928 | ppl    1.019\n",
            "\n",
            "=====PRETRAINED MODEL======\n",
            "| epoch   1 |    50/  200 steps | loss 0.81027 | ppl    2.249\n",
            "| epoch   1 |   100/  200 steps | loss 0.70175 | ppl    2.017\n",
            "| epoch   1 |   150/  200 steps | loss 0.56988 | ppl    1.768\n",
            "| epoch   2 |    50/  200 steps | loss 0.48984 | ppl    1.632\n",
            "| epoch   2 |   100/  200 steps | loss 0.50942 | ppl    1.664\n",
            "| epoch   2 |   150/  200 steps | loss 0.52380 | ppl    1.688\n",
            "| epoch   3 |    50/  200 steps | loss 0.40909 | ppl    1.505\n",
            "| epoch   3 |   100/  200 steps | loss 0.41487 | ppl    1.514\n",
            "| epoch   3 |   150/  200 steps | loss 0.41964 | ppl    1.521\n",
            "| epoch   4 |    50/  200 steps | loss 0.32793 | ppl    1.388\n",
            "| epoch   4 |   100/  200 steps | loss 0.31124 | ppl    1.365\n",
            "| epoch   4 |   150/  200 steps | loss 0.38850 | ppl    1.475\n",
            "| epoch   5 |    50/  200 steps | loss 0.20164 | ppl    1.223\n",
            "| epoch   5 |   100/  200 steps | loss 0.35890 | ppl    1.432\n",
            "| epoch   5 |   150/  200 steps | loss 0.25842 | ppl    1.295\n",
            "| epoch   6 |    50/  200 steps | loss 0.18757 | ppl    1.206\n",
            "| epoch   6 |   100/  200 steps | loss 0.14886 | ppl    1.161\n",
            "| epoch   6 |   150/  200 steps | loss 0.30667 | ppl    1.359\n",
            "| epoch   7 |    50/  200 steps | loss 0.18721 | ppl    1.206\n",
            "| epoch   7 |   100/  200 steps | loss 0.16210 | ppl    1.176\n",
            "| epoch   7 |   150/  200 steps | loss 0.22458 | ppl    1.252\n",
            "| epoch   8 |    50/  200 steps | loss 0.15947 | ppl    1.173\n",
            "| epoch   8 |   100/  200 steps | loss 0.15959 | ppl    1.173\n",
            "| epoch   8 |   150/  200 steps | loss 0.23584 | ppl    1.266\n",
            "| epoch   9 |    50/  200 steps | loss 0.11821 | ppl    1.125\n",
            "| epoch   9 |   100/  200 steps | loss 0.13176 | ppl    1.141\n",
            "| epoch   9 |   150/  200 steps | loss 0.16574 | ppl    1.180\n",
            "| epoch  10 |    50/  200 steps | loss 0.03532 | ppl    1.036\n",
            "| epoch  10 |   100/  200 steps | loss 0.03900 | ppl    1.040\n",
            "| epoch  10 |   150/  200 steps | loss 0.12161 | ppl    1.129\n",
            "| epoch  11 |    50/  200 steps | loss 0.03738 | ppl    1.038\n",
            "| epoch  11 |   100/  200 steps | loss 0.02771 | ppl    1.028\n",
            "| epoch  11 |   150/  200 steps | loss 0.04503 | ppl    1.046\n",
            "| epoch  12 |    50/  200 steps | loss 0.04657 | ppl    1.048\n",
            "| epoch  12 |   100/  200 steps | loss 0.01284 | ppl    1.013\n",
            "| epoch  12 |   150/  200 steps | loss 0.05532 | ppl    1.057\n",
            "| epoch  13 |    50/  200 steps | loss 0.01995 | ppl    1.020\n",
            "| epoch  13 |   100/  200 steps | loss 0.02429 | ppl    1.025\n",
            "| epoch  13 |   150/  200 steps | loss 0.03005 | ppl    1.031\n",
            "| epoch  14 |    50/  200 steps | loss 0.03913 | ppl    1.040\n",
            "| epoch  14 |   100/  200 steps | loss 0.01692 | ppl    1.017\n",
            "| epoch  14 |   150/  200 steps | loss 0.02737 | ppl    1.028\n",
            "| epoch  15 |    50/  200 steps | loss 0.01525 | ppl    1.015\n",
            "| epoch  15 |   100/  200 steps | loss 0.00414 | ppl    1.004\n",
            "| epoch  15 |   150/  200 steps | loss 0.05754 | ppl    1.059\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from_scratch_settings = [True, False]\n",
        "\n",
        "from_scratch_valid_acc = []\n",
        "pretrained_valid_acc = []\n",
        "lr = 0.0001\n",
        "\n",
        "for from_scratch in from_scratch_settings:\n",
        "    model = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    if not from_scratch:\n",
        "        print(\"=====PRETRAINED MODEL======\")\n",
        "        #load checkpoint\n",
        "        checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n",
        "        #load state dict\n",
        "        model.base.load_state_dict(checkpoint['model_state_dict'])\n",
        "    else:\n",
        "        print(\"=====Trainig FROM SCRATCH======\")\n",
        "    epochs = 15\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(\n",
        "            path_data_train,\n",
        "            path_labels_train,\n",
        "            save_interval=-1,\n",
        "            task='classification',\n",
        "            batch_size=8,\n",
        "            log_interval=50,\n",
        "        )\n",
        "        acc = evaluate_accuracy(\n",
        "            get_loader(\n",
        "                path_data_valid,\n",
        "                path_labels_valid,\n",
        "                token2ind=token2ind,\n",
        "                batch_size=20,\n",
        "                task='classification',\n",
        "            )\n",
        "        )\n",
        "        if from_scratch:\n",
        "            from_scratch_valid_acc.append(acc)\n",
        "        else:\n",
        "            pretrained_valid_acc.append(acc)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "RCpBIdTHojm6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "ed1c0cbe-337e-4f82-d113-b965101ef9f2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Visualize the accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(from_scratch_valid_acc, label = \"From Scratch\")\n",
        "plt.plot(pretrained_valid_acc, label = \"Pretrained\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.6.15 ('altegrad')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "1f3cfdeab8dd8f9900bd16266619de191cf0f5e09365d74b1fba1714dce58066"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}